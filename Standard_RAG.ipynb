{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPd0d6FZJQB4wObO3UcFaXt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fe6e863c71ee438eb5696303cf4b1fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87a3ce7de22d40c89ae50df5e0f833f9",
              "IPY_MODEL_efdf6446c2a34ccda0516973a844711a",
              "IPY_MODEL_3805d52e4c4c4ec4adb8b8db314f2573",
              "IPY_MODEL_5ba74d5478ca4c5f84083a474a1200cb"
            ],
            "layout": "IPY_MODEL_a05e8419e4ea4eb48d6d646a69cce00a"
          }
        },
        "985900c2cb924914ae58d40b4438dc5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b24540088bf54c76ba2507d0df3e4c4f",
            "placeholder": "​",
            "style": "IPY_MODEL_688f10a356904587b189d9e22fc91dec",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "a145be8e9316457da6d75e8017c7b4fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_548d49e73691458da446987683049f13",
            "placeholder": "​",
            "style": "IPY_MODEL_0f5dc3342af946f491bccc9469d4d5e5",
            "value": ""
          }
        },
        "ecf98737de444bbb96fa9c00e9d3e15e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_8f109d7dd5244a288f3dd640740dcad0",
            "style": "IPY_MODEL_39110491075e46b1bfa2d2d28b18e33e",
            "value": true
          }
        },
        "4d93ad33f1b94ae5907edf4c5249fde1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8b83f486ae324992b5d01e817dd71f5f",
            "style": "IPY_MODEL_5b60eb3c646c479ea09c72fdbf647435",
            "tooltip": ""
          }
        },
        "cf15d20381c944408ecaea13e2c2a87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04c6880a9f994f9b8560ea3332677610",
            "placeholder": "​",
            "style": "IPY_MODEL_c5459a9d2bb746298fd3510a853fccae",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "a05e8419e4ea4eb48d6d646a69cce00a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "b24540088bf54c76ba2507d0df3e4c4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "688f10a356904587b189d9e22fc91dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "548d49e73691458da446987683049f13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f5dc3342af946f491bccc9469d4d5e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f109d7dd5244a288f3dd640740dcad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39110491075e46b1bfa2d2d28b18e33e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b83f486ae324992b5d01e817dd71f5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b60eb3c646c479ea09c72fdbf647435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "04c6880a9f994f9b8560ea3332677610": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5459a9d2bb746298fd3510a853fccae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e19506220e7e415f96b7399fd3a44705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ea2691d999c4446a0d6f9b53df1418d",
            "placeholder": "​",
            "style": "IPY_MODEL_8488eb3db7814db08a097583e1ffbee7",
            "value": "Connecting..."
          }
        },
        "2ea2691d999c4446a0d6f9b53df1418d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8488eb3db7814db08a097583e1ffbee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87a3ce7de22d40c89ae50df5e0f833f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6a20270f72644638e4c069333274252",
            "placeholder": "​",
            "style": "IPY_MODEL_3a9271ea7ccb4c79a11f1b097c20dbef",
            "value": "Token is valid (permission: read)."
          }
        },
        "efdf6446c2a34ccda0516973a844711a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74a67bd88f7c4305b8d1262bf8c55c33",
            "placeholder": "​",
            "style": "IPY_MODEL_f3367a545e784dd7bb2ed28bcec9e883",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "3805d52e4c4c4ec4adb8b8db314f2573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2359e2a76a3c4da6a04f6a67656ee3ad",
            "placeholder": "​",
            "style": "IPY_MODEL_56f69571d04b424dbe0fe4f9b7ce7304",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "5ba74d5478ca4c5f84083a474a1200cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2a114febc7d422a97c8bf101d5369d5",
            "placeholder": "​",
            "style": "IPY_MODEL_287b12c14ee344c6bdbad49caf322296",
            "value": "Login successful"
          }
        },
        "b6a20270f72644638e4c069333274252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a9271ea7ccb4c79a11f1b097c20dbef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74a67bd88f7c4305b8d1262bf8c55c33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3367a545e784dd7bb2ed28bcec9e883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2359e2a76a3c4da6a04f6a67656ee3ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56f69571d04b424dbe0fe4f9b7ce7304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2a114febc7d422a97c8bf101d5369d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "287b12c14ee344c6bdbad49caf322296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b24a24cb9684fbdb79dfd05148c861c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35b5bff614064b43a4ed656d6dc1417e",
              "IPY_MODEL_f874d74f59cc4471963787d472c73b7d",
              "IPY_MODEL_df62d3af82a04657a6e75c4ccef86fa9"
            ],
            "layout": "IPY_MODEL_56472881562d498486368c48f694db72"
          }
        },
        "35b5bff614064b43a4ed656d6dc1417e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07630c3088a54e8284c460ec9a0aa3bd",
            "placeholder": "​",
            "style": "IPY_MODEL_7afc99e65af74833a15ffcbdfbf17ade",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f874d74f59cc4471963787d472c73b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_641cb23f534a4d69a67c7f15f8b4bd12",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdd59c823f504dd79ab8b69e583c06ed",
            "value": 2
          }
        },
        "df62d3af82a04657a6e75c4ccef86fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a1589f8eabf411f9177c29dd33e4089",
            "placeholder": "​",
            "style": "IPY_MODEL_50cd79ba768f4f7f83a17f145b3b7048",
            "value": " 2/2 [00:05&lt;00:00,  2.52s/it]"
          }
        },
        "56472881562d498486368c48f694db72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07630c3088a54e8284c460ec9a0aa3bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7afc99e65af74833a15ffcbdfbf17ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "641cb23f534a4d69a67c7f15f8b4bd12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdd59c823f504dd79ab8b69e583c06ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a1589f8eabf411f9177c29dd33e4089": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50cd79ba768f4f7f83a17f145b3b7048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sainiakhil/RAG-Chat-Bot-Streamlit/blob/main/Standard_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu\n",
        "!pip install PyPDF2\n",
        "!pip install bitsandbytes\n",
        "!pip install sentence-transformers\n",
        "!pip install transformers\n",
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "tES42laLUVby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import BitsAndBytesConfig\n",
        "import PyPDF2\n",
        "import os\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "KAQ1UThFU21c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "fe6e863c71ee438eb5696303cf4b1fb9",
            "985900c2cb924914ae58d40b4438dc5b",
            "a145be8e9316457da6d75e8017c7b4fe",
            "ecf98737de444bbb96fa9c00e9d3e15e",
            "4d93ad33f1b94ae5907edf4c5249fde1",
            "cf15d20381c944408ecaea13e2c2a87f",
            "a05e8419e4ea4eb48d6d646a69cce00a",
            "b24540088bf54c76ba2507d0df3e4c4f",
            "688f10a356904587b189d9e22fc91dec",
            "548d49e73691458da446987683049f13",
            "0f5dc3342af946f491bccc9469d4d5e5",
            "8f109d7dd5244a288f3dd640740dcad0",
            "39110491075e46b1bfa2d2d28b18e33e",
            "8b83f486ae324992b5d01e817dd71f5f",
            "5b60eb3c646c479ea09c72fdbf647435",
            "04c6880a9f994f9b8560ea3332677610",
            "c5459a9d2bb746298fd3510a853fccae",
            "e19506220e7e415f96b7399fd3a44705",
            "2ea2691d999c4446a0d6f9b53df1418d",
            "8488eb3db7814db08a097583e1ffbee7",
            "87a3ce7de22d40c89ae50df5e0f833f9",
            "efdf6446c2a34ccda0516973a844711a",
            "3805d52e4c4c4ec4adb8b8db314f2573",
            "5ba74d5478ca4c5f84083a474a1200cb",
            "b6a20270f72644638e4c069333274252",
            "3a9271ea7ccb4c79a11f1b097c20dbef",
            "74a67bd88f7c4305b8d1262bf8c55c33",
            "f3367a545e784dd7bb2ed28bcec9e883",
            "2359e2a76a3c4da6a04f6a67656ee3ad",
            "56f69571d04b424dbe0fe4f9b7ce7304",
            "b2a114febc7d422a97c8bf101d5369d5",
            "287b12c14ee344c6bdbad49caf322296"
          ]
        },
        "id": "YqmPsUVIYZMQ",
        "outputId": "6f2aba4c-d359-449d-fd35-93ead834435c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe6e863c71ee438eb5696303cf4b1fb9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eSD3SY_MCBov"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
      ],
      "metadata": {
        "id": "PuRMLU6YCIJu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "    # Load the model\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(\n",
        "        \"meta-llama/Llama-2-7b-chat-hf\",\n",
        "        device_map = device,\n",
        "        quantization_config = bnb_config,\n",
        "        torch_dtype=torch.float16,\n",
        "        low_cpu_mem_usage=True,\n",
        "    )\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
        "\n",
        "\n",
        "# Text generation pipeline for LLM\n",
        "generator = pipeline('text-generation', model=llm_model, tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2b24a24cb9684fbdb79dfd05148c861c",
            "35b5bff614064b43a4ed656d6dc1417e",
            "f874d74f59cc4471963787d472c73b7d",
            "df62d3af82a04657a6e75c4ccef86fa9",
            "56472881562d498486368c48f694db72",
            "07630c3088a54e8284c460ec9a0aa3bd",
            "7afc99e65af74833a15ffcbdfbf17ade",
            "641cb23f534a4d69a67c7f15f8b4bd12",
            "fdd59c823f504dd79ab8b69e583c06ed",
            "9a1589f8eabf411f9177c29dd33e4089",
            "50cd79ba768f4f7f83a17f145b3b7048"
          ]
        },
        "id": "FknpyfsOCIn2",
        "outputId": "5db741b7-17e6-4de7-e69c-0d21195cb3eb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b24a24cb9684fbdb79dfd05148c861c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_reader = PyPDF2.PdfReader('/content/attention-is-all-you-need-Paper.pdf')\n",
        "pdf_text = \"\"\n",
        "\n",
        "    # Extract text from each page\n",
        "for page_num in range(len(pdf_reader.pages)):\n",
        "    page = pdf_reader.pages[page_num]\n",
        "    pdf_text += page.extract_text()\n",
        "\n",
        "# Split the PDF content into chunks for better embedding\n",
        "doc_chunks = [pdf_text[i:i+500] for i in range(0, len(pdf_text), 500)]\n"
      ],
      "metadata": {
        "id": "0IoMMDGGCvqU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = embedding_model.encode(doc_chunks)\n",
        "vectors = np.array(vectors, dtype=np.float32)\n",
        "\n",
        "\n",
        "# Initialize FAISS index\n",
        "dimension = vectors.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(np.array(vectors))"
      ],
      "metadata": {
        "id": "1a-TpQesC3sG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_context(query, top_k=3):\n",
        "    # Embed the user query\n",
        "    query_vector = embedding_model.encode([query])\n",
        "\n",
        "    # Search for top-k relevant documents in FAISS\n",
        "    distances, indices = index.search(np.array(query_vector, dtype=np.float32), top_k)\n",
        "\n",
        "    # Retrieve relevant document chunks\n",
        "    retrieved_docs = [doc_chunks[i] for i in indices[0]]\n",
        "\n",
        "    return retrieved_docs\n",
        "\n",
        "def generate_answer(query):\n",
        "\n",
        "    context = retrieve_context(query)\n",
        "\n",
        "    # Augment the query with context\n",
        "    augmented_input = query + \"\\n\\n Context:\\n\" + \"\\n\".join(context) + \"\\n\\n Final Answer:\\n\"\n",
        "\n",
        "    inputs = tokenizer(augmented_input, return_tensors=\"pt\").to('cuda')\n",
        "    output = llm_model.generate(**inputs, max_new_tokens=500)\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "8UEil-oPC6gB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question to the QA bot\n",
        "query = \"what is multi head attention\"\n",
        "\n",
        "# Get the answer using the QA bot\n",
        "answer = generate_answer(query)\n",
        "print(\"Answer:\", answer)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm3XBFbaC8Ph",
        "outputId": "84e58866-4e77-4379-c101-6700e2ee46eb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: what is multi head attention\n",
            "\n",
            " Context:\n",
            "r this is\n",
            "reduced to a constant number of operations, albeit at the cost of reduced effective resolution due\n",
            "to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\n",
            "described in section 3.2.\n",
            "Self-attention, sometimes called intra-attention is an attention mechanism relating different positions\n",
            "of a single sequence in order to compute a representation of the sequence. Self-attention has been\n",
            "used successfully in a variety of tasks including reading comprehe\n",
            "ion. (right) Multi-Head Attention consists of several\n",
            "attention layers running in parallel.\n",
            "query with all keys, divide each bypdk, and apply a softmax function to obtain the weights on the\n",
            "values.\n",
            "In practice, we compute the attention function on a set of queries simultaneously, packed together\n",
            "into a matrix Q. The keys and values are also packed together into matrices KandV. We compute\n",
            "the matrix of outputs as:\n",
            "Attention(Q;K;V ) = softmax(QKT\n",
            "pdk)V (1)\n",
            "The two most commonly used attention func\n",
            "2Rdmodel\u0002dv\n",
            "andWO2Rhdv\u0002dmodel.\n",
            "In this work we employ h= 8 parallel attention layers, or heads. For each of these we use\n",
            "dk=dv=dmodel=h= 64 . Due to the reduced dimension of each head, the total computational cost\n",
            "is similar to that of single-head attention with full dimensionality.\n",
            "3.2.3 Applications of Attention in our Model\n",
            "The Transformer uses multi-head attention in three different ways:\n",
            "\u000fIn \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\n",
            "and the memory\n",
            "\n",
            " Final Answer:\n",
            "\n",
            "Multi-head attention is a type of attention mechanism used in the Transformer architecture. It allows the model to attend to different parts of the input sequence simultaneously, and to weigh the importance of each part when computing the output. In the Transformer, multi-head attention is used in three different ways:\n",
            "\n",
            "1. Encoder-decoder attention: In this case, the queries come from the previous decoder layer, and the memory is the input sequence. This allows the model to attend to different parts of the input sequence as it generates the output.\n",
            "2. Decoder attention: In this case, the queries come from the previous encoder layer, and the memory is the input sequence. This allows the model to attend to different parts of the input sequence as it generates the output.\n",
            "3. Self-attention: In this case, the queries and keys are both from the same layer, and the memory is the input sequence. This allows the model to attend to different parts of the input sequence within the same layer.\n",
            "\n",
            "The multi-head attention mechanism is computed as follows:\n",
            "\n",
            "Q, K, and V are matrices representing the queries, keys, and values, respectively. The attention function is computed as:\n",
            "\n",
            "Attention(Q, K, V) = softmax(QK^T/d)V\n",
            "\n",
            "where d is the dimensionality of the input sequence.\n",
            "\n",
            "In the Transformer, the attention mechanism is applied multiple times in parallel, with each application using a different set of queries, keys, and values. This is known as multi-head attention, and it allows the model to attend to different parts of the input sequence simultaneously.\n",
            "\n",
            "The benefits of multi-head attention include:\n",
            "\n",
            "* It allows the model to capture longer-range dependencies in the input sequence.\n",
            "* It allows the model to capture different types of relationships between different parts of the input sequence.\n",
            "* It reduces the computational cost of attention, since the attention function is computed multiple times in parallel.\n",
            "\n",
            "In summary, multi-head attention is a powerful attention mechanism used in the Transformer architecture to improve the model's ability to capture longer-range dependencies in the input sequence, and to reduce the computational cost of attention.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question to the QA bot\n",
        "query = \"what is self attention\"\n",
        "\n",
        "# Get the answer using the QA bot\n",
        "answer = generate_answer(query)\n",
        "print(\"Answer:\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18Ug4KBObkQG",
        "outputId": "d28c1cba-57ff-410c-d819-3b0d29b92adc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: what is self attention\n",
            "\n",
            " Context:\n",
            "r this is\n",
            "reduced to a constant number of operations, albeit at the cost of reduced effective resolution due\n",
            "to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\n",
            "described in section 3.2.\n",
            "Self-attention, sometimes called intra-attention is an attention mechanism relating different positions\n",
            "of a single sequence in order to compute a representation of the sequence. Self-attention has been\n",
            "used successfully in a variety of tasks including reading comprehe\n",
            "n terms of\n",
            "computational complexity, self-attention layers are faster than recurrent layers when the sequence\n",
            "lengthnis smaller than the representation dimensionality d, which is most often the case with\n",
            "sentence representations used by state-of-the-art models in machine translations, such as word-piece\n",
            "[31] and byte-pair [ 25] representations. To improve computational performance for tasks involving\n",
            "very long sequences, self-attention could be restricted to considering only a neighborhood of si\n",
            "ion. (right) Multi-Head Attention consists of several\n",
            "attention layers running in parallel.\n",
            "query with all keys, divide each bypdk, and apply a softmax function to obtain the weights on the\n",
            "values.\n",
            "In practice, we compute the attention function on a set of queries simultaneously, packed together\n",
            "into a matrix Q. The keys and values are also packed together into matrices KandV. We compute\n",
            "the matrix of outputs as:\n",
            "Attention(Q;K;V ) = softmax(QKT\n",
            "pdk)V (1)\n",
            "The two most commonly used attention func\n",
            "\n",
            " Final Answer:\n",
            "Self-attention is an attention mechanism that relates different positions of a single sequence to compute a representation of the sequence. It is also known as intra-attention. Self-attention is used to improve the computational complexity of tasks involving very long sequences by reducing the number of operations required to compute the attention weights. Multi-Head Attention is a variation of self-attention that consists of several attention layers running in parallel, each with its own set of queries, keys, and values.\n",
            "\n",
            "Self-attention is a powerful tool for modeling sequential data, as it allows the model to capture long-range dependencies and contextual relationships within a sequence. Self-attention can be used in various natural language processing (NLP) tasks such as language translation, question answering, and text summarization.\n",
            "\n",
            "In self-attention, the input sequence is first transformed into a set of vectors, called keys, values, and queries. The keys and values represent the context of the sequence, while the queries represent the input sequence. The attention function is then computed by taking the dot product of the queries and keys, normalizing the results, and applying a softmax function to obtain a set of attention weights. These attention weights are then used to compute a weighted sum of the values, resulting in a representation of the input sequence.\n",
            "\n",
            "Multi-Head Attention is a variation of self-attention that allows the model to jointly attend to information from different representation subspaces at different positions. This is achieved by computing multiple attention functions in parallel, each with its own set of queries, keys, and values. The outputs of each attention function are then combined to form the final representation of the input sequence.\n",
            "\n",
            "Self-attention has several advantages over traditional recurrent neural network (RNN) architectures. First, it allows the model to capture long-range dependencies and contextual relationships within a sequence, without requiring recurrence. Second, it reduces the computational complexity of the attention mechanism, making it more efficient for tasks involving very long sequences. Finally, self-attention allows the model to capture multiple attention patterns simultaneously, which can improve the overall performance of the model.\n",
            "\n",
            "In summary, self-attention is a powerful attention mechanism that allows the model to capture contextual relationships within a sequence. Multi-Head Attention is a variation of self-attention that allows the model to jointly attend to information from\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question to the QA bot\n",
        "query = \"what is transformers in attention all you need paper\"\n",
        "\n",
        "# Get the answer using the QA bot\n",
        "answer = generate_answer(query)\n",
        "print(\"Answer:\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFMV1cHmb8Un",
        "outputId": "12e4c2c4-2372-40d4-f698-ce689a8f8e5e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: what is transformers in attention all you need paper\n",
            "\n",
            " Context:\n",
            "tention-based models and plan to apply them to other tasks. We\n",
            "plan to extend the Transformer to problems involving input and output modalities other than text and\n",
            "to investigate local, restricted attention mechanisms to efﬁciently handle large inputs and outputs\n",
            "such as images, audio and video. Making generation less sequential is another research goals of ours.\n",
            "The code we used to train and evaluate our models is available at https://github.com/\n",
            "tensorflow/tensor2tensor .\n",
            "Acknowledgements We a\n",
            "nsion, abstractive summarization,\n",
            "textual entailment and learning task-independent sentence representations [4, 22, 23, 19].\n",
            "End-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\n",
            "aligned recurrence and have been shown to perform well on simple-language question answering and\n",
            "language modeling tasks [28].\n",
            "To the best of our knowledge, however, the Transformer is the ﬁrst transduction model relying\n",
            "entirely on self-attention to compute representations of its \n",
            "tions are additive attention [ 2], and dot-product (multi-\n",
            "plicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\n",
            "of1pdk. Additive attention computes the compatibility function using a feed-forward network with\n",
            "a single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\n",
            "much faster and more space-efﬁcient in practice, since it can be implemented using highly optimized\n",
            "matrix multiplication code.\n",
            "While for \n",
            "\n",
            " Final Answer:\n",
            "The Transformer model proposed in the paper \"Attention Is All You Need\" by Vaswani et al. in 2017 is a type of neural network architecture that relies entirely on self-attention mechanisms to compute representations of input sequences. The Transformer model is designed for sequence-to-sequence tasks, such as machine translation, and it has been shown to achieve state-of-the-art results on several benchmark datasets.\n",
            "\n",
            "The Transformer model is based on the idea of multi-head attention, which allows the model to attend to different parts of the input sequence simultaneously and combine their representations. The model uses a self-attention mechanism to compute the compatibility between each element in the input sequence and the entire sequence, and it uses a feed-forward network to transform the computed representations into the final output.\n",
            "\n",
            "The Transformer model is different from other attention-based models in that it does not use any recurrent neural networks (RNNs) or convolutional neural networks (CNNs). Instead, it relies solely on the self-attention mechanism to capture the long-range dependencies in the input sequence. This allows the model to parallelize the computation of attention over the input sequence, making it much faster and more scalable than other attention-based models.\n",
            "\n",
            "The Transformer model has been applied to a wide range of sequence-to-sequence tasks, including machine translation, text summarization, and text generation. It has also been used as a building block for other models, such as the BERT (Bidirectional Encoder Representations from Transformers) model, which has achieved state-of-the-art results on many natural language processing (NLP) tasks.\n",
            "\n",
            "In summary, the Transformer model is a type of neural network architecture that relies entirely on self-attention mechanisms to compute representations of input sequences. It has been shown to achieve state-of-the-art results on several sequence-to-sequence tasks and has been widely adopted in the NLP community.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question to the QA bot\n",
        "query = \"what is positional encoding in transformers\"\n",
        "\n",
        "# Get the answer using the QA bot\n",
        "answer = generate_answer(query)\n",
        "print(\"Answer:\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzHbw5G9cYmG",
        "outputId": "06333c5e-7269-44bf-ff8d-d5d9cb752b47"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: what is positional encoding in transformers\n",
            "\n",
            " Context:\n",
            "=r)\n",
            "bottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\n",
            "as the embeddings, so that the two can be summed. There are many choices of positional encodings,\n",
            "learned and ﬁxed [8].\n",
            "In this work, we use sine and cosine functions of different frequencies:\n",
            "PE(pos;2i)=sin(pos=100002i=d model)\n",
            "PE(pos;2i+1)=cos(pos=100002i=d model)\n",
            "whereposis the position and iis the dimension. That is, each dimension of the positional encoding\n",
            "corresponds to a sinusoid. The w\n",
            "then generates an output\n",
            "sequence (y1;:::;y m)of symbols one element at a time. At each step the model is auto-regressive\n",
            "[9], consuming the previously generated symbols as additional input when generating the next.\n",
            "The Transformer follows this overall architecture using stacked self-attention and point-wise, fully\n",
            "connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\n",
            "respectively.\n",
            "3.1 Encoder and Decoder Stacks\n",
            "Encoder: The encoder is composed of a s\n",
            "input and output without using sequence-\n",
            "aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\n",
            "self-attention and discuss its advantages over models such as [14, 15] and [8].\n",
            "3 Model Architecture\n",
            "Most competitive neural sequence transduction models have an encoder-decoder structure [ 5,2,29].\n",
            "Here, the encoder maps an input sequence of symbol representations (x1;:::;x n)to a sequence\n",
            "of continuous representations z= (z1;:::;z n). Given z, the decoder \n",
            "\n",
            " Final Answer:\n",
            "Positional encoding is a technique used in transformer models to incorporate positional information into the input sequence. It is typically applied to the input embeddings before they are fed into the transformer architecture. The idea is to add a sinusoidal function of position to the embedding, which captures the positional information of the input sequence. This allows the model to capture long-range dependencies and better handle input sequences of varying lengths.\n",
            "\n",
            "In the transformer architecture, the positional encoding is applied to the bottom of the encoder and decoder stacks. The positional encodings have the same dimension as the embeddings, so they can be summed. The transformer uses sine and cosine functions of different frequencies as the positional encoding. The idea is to generate an output sequence (y1;:::;y m) of symbols one element at a time, where each dimension of the positional encoding corresponds to a sinusoid.\n",
            "\n",
            "The transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and decoder. The encoder is composed of a single input and output without using sequence-aligned RNNs or convolution. The decoder maps a sequence of continuous representations (z1;:::;z n) to an output sequence of symbols (y1;:::;y m).\n",
            "\n",
            "The advantages of using positional encoding in transformer models are:\n",
            "\n",
            "* Captures long-range dependencies: Positional encoding allows the model to capture long-range dependencies in the input sequence, which is important for tasks such as language translation.\n",
            "* Handles input sequences of varying lengths: By incorporating positional information into the input embeddings, the model can handle input sequences of varying lengths without losing important contextual information.\n",
            "* Improves performance: Positional encoding has been shown to improve the performance of transformer models on various natural language processing tasks.\n",
            "\n",
            "In summary, positional encoding is a technique used in transformer models to incorporate positional information into the input sequence. It is applied to the input embeddings before they are fed into the transformer architecture, and it captures long-range dependencies and handles input sequences of varying lengths.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question to the QA bot\n",
        "query = \"what is YOLOV8\"\n",
        "\n",
        "# Get the answer using the QA bot\n",
        "answer = generate_answer(query)\n",
        "print(\"Answer:\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tanLlt7dcr_E",
        "outputId": "71c6d216-411e-4130-cd59-65cf2d18f3d5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No relevant documents found for the query.\n",
            "Answer: No relevant information was found to answer your query.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question to the QA bot\n",
        "query = \"what decoder contains in transformers architecture\"\n",
        "\n",
        "# Get the answer using the QA bot\n",
        "answer = generate_answer(query)\n",
        "print(\"Answer:\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEQ5-WmXf5eU",
        "outputId": "53ce8200-a364-4441-c659-d69e63b38732"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: what decoder contains in transformers architecture\n",
            "\n",
            " Context:\n",
            "ilitate these residual connections, all sub-layers in the model, as well as the embedding\n",
            "layers, produce outputs of dimension dmodel = 512 .\n",
            "Decoder: The decoder is also composed of a stack of N= 6identical layers. In addition to the two\n",
            "sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\n",
            "attention over the output of the encoder stack. Similar to the encoder, we employ residual connections\n",
            "around each of the sub-layers, followed by layer normalizat\n",
            "then generates an output\n",
            "sequence (y1;:::;y m)of symbols one element at a time. At each step the model is auto-regressive\n",
            "[9], consuming the previously generated symbols as additional input when generating the next.\n",
            "The Transformer follows this overall architecture using stacked self-attention and point-wise, fully\n",
            "connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\n",
            "respectively.\n",
            "3.1 Encoder and Decoder Stacks\n",
            "Encoder: The encoder is composed of a s\n",
            "input and output without using sequence-\n",
            "aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\n",
            "self-attention and discuss its advantages over models such as [14, 15] and [8].\n",
            "3 Model Architecture\n",
            "Most competitive neural sequence transduction models have an encoder-decoder structure [ 5,2,29].\n",
            "Here, the encoder maps an input sequence of symbol representations (x1;:::;x n)to a sequence\n",
            "of continuous representations z= (z1;:::;z n). Given z, the decoder \n",
            "\n",
            " Final Answer:\n",
            "The decoder in Transformers architecture contains multi-head attention over the output of the encoder stack, followed by layer normalization, feed-forward network, and residual connections.\n",
            "\n",
            "In more detail, the decoder is composed of a stack of N=6 identical layers, each of which consists of:\n",
            "\n",
            "* Two sub-layers in each layer, which perform multi-head attention over the output of the encoder stack and then perform layer normalization.\n",
            "* A feed-forward network (FFN) that takes the output of the sub-layers and applies a non-linear transformation.\n",
            "* Residual connections that allow the model to learn the residual between the input and the output of each sub-layer.\n",
            "\n",
            "The decoder generates an output sequence (y1;:::;y m) of symbols one element at a time, using an auto-regressive approach. At each step, the model is given the previously generated symbols as additional input when generating the next symbol.\n",
            "\n",
            "The Transformer architecture uses stacked self-attention and point-wise, fully connected layers for both the encoder and decoder. The encoder takes the input sequence and outputs a sequence of continuous representations, while the decoder takes the continuous representations and generates an output sequence of symbols.\n",
            "\n",
            "The Transformer architecture has several advantages over other neural sequence transduction models. It does not use sequence-aligned RNNs or convolution, which can be computationally expensive and difficult to train. Instead, it uses self-attention mechanisms to process the input sequence in parallel, allowing it to handle long input sequences efficiently. Additionally, the Transformer architecture is more parallelizable than other models, which can make it easier to train and deploy.\n"
          ]
        }
      ]
    }
  ]
}